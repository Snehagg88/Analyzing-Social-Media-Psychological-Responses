# -*- coding: utf-8 -*-
"""SOSH-AURA:  Unveiling Social Media Emotions with ML

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bGxBAfuktXlcT_rTByJY8dGJUtMMQ3ZW
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

from google.colab import files
upload = files.upload()

data = pd.read_csv('SocialMedia.csv')

data.head()

data.isna().sum()

"""#**DATA ANALYSIS**"""

# Set an theme
sns.set_theme(style="whitegrid", palette="pastel")

"""###Demographic Analysis

"""

#Age Distribution
plt.figure(figsize=(8, 6))
sns.histplot(data['Age'], kde=True, bins=15, color="skyblue")
plt.title('Age Distribution', fontsize=16)
plt.xlabel('Age', fontsize=14)
plt.ylabel('Frequency', fontsize=14)
plt.show()

#Gender Breakdown
plt.figure(figsize=(8, 6))
colors = sns.color_palette("pastel")
data['Gender'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=140, colors=colors)
plt.title('Gender Breakdown', fontsize=16)
plt.ylabel('')
plt.show()

#Demographics Breakdown
plt.figure(figsize=(8, 6))
colors = sns.color_palette("pastel")
data['Demographics'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=140, colors=colors)
plt.title('Demographics Breakdown', fontsize=16)
plt.ylabel('')
plt.show()

#Location Distribution
plt.figure(figsize=(7, 5))
sns.countplot(y='Location', data=data, order=data['Location'].value_counts().index, palette="coolwarm")
plt.title('Location Distribution', fontsize=16)
plt.xlabel('Count', fontsize=14)
plt.ylabel('Location', fontsize=14)
plt.show()

"""###Platform Usage Analysis"""

#Platform Popularity
plt.figure(figsize=(8, 6))
sns.countplot(x='Platform', data=data, order=data['Platform'].value_counts().index, palette="muted")
plt.title('Platform Popularity', fontsize=16)
plt.xlabel('Platform', fontsize=14)
plt.ylabel('Count', fontsize=14)
plt.show()

#Time Spent by Platform
plt.figure(figsize=(8, 6))
sns.boxplot(x='Platform', y='Total Time Spent', data=data, palette="husl")
plt.title('Time Spent by Platform', fontsize=16)
plt.xlabel('Platform', fontsize=14)
plt.ylabel('Total Time Spent', fontsize=14)
plt.show()

#Time Spent by Platform
plt.figure(figsize=(8, 6))
sns.boxplot(x='Video Length', y='Total Time Spent', data=data, palette="husl")
plt.title('Time Spent On Video', fontsize=16)
plt.xlabel('Video Length', fontsize=14)
plt.ylabel('Time Spent On Video', fontsize=14)
plt.show()

# Line Plot: Frequency of login vs. Addiction Level
plt.figure(figsize=(10, 6))
plt.plot(data['Frequency'], data['Addiction Level'], marker='o', linestyle='-', color='b')
plt.title('Frequency of Login vs. Addiction Level')
plt.xlabel('Frequency of Login')
plt.ylabel('Addiction Level')
plt.grid(True)
plt.show()

#Sessions per Platform
plt.figure(figsize=(8, 6))
sns.barplot(x='Platform', y='Number of Sessions', data=data, palette="Blues_d")
plt.title('Sessions per Platform', fontsize=16)
plt.xlabel('Platform', fontsize=14)
plt.ylabel('Average Number of Sessions', fontsize=14)
plt.show()

"""### Engagement Metrics"""

#Engagement vs. Platform
plt.figure(figsize=(8, 6))
sns.barplot(x='Platform', y='Engagement', data=data, palette="magma")
plt.title('Engagement vs. Platform', fontsize=16)
plt.xlabel('Platform', fontsize=14)
plt.ylabel('Average Engagement', fontsize=14)
plt.show()

#Video Category popularity
plt.figure(figsize=(8, 6))
sns.barplot(x=data['Video Category'].value_counts().index, y=data['Video Category'].value_counts().values, palette="Spectral")
plt.title('Video Category Popularity', fontsize=16)
plt.xlabel('Video Category', fontsize=14)
plt.ylabel('Count', fontsize=14)
plt.xticks(rotation=45)
plt.show()

#Number of Videos Watched vs. Engagement
plt.figure(figsize=(8, 6))
sns.scatterplot(x='Number of Videos Watched', y='Engagement', data=data, color="darkred")
plt.title('Number of Videos Watched vs. Engagement', fontsize=16)
plt.xlabel('Number of Videos Watched', fontsize=14)
plt.ylabel('Engagement', fontsize=14)
plt.show()

"""###User Behavior"""

#Watch Time Distribution
plt.figure(figsize=(10, 6))
sns.histplot(pd.to_datetime(data['Watch Time'], format='%I:%M %p').dt.hour, bins=24, kde=True, color="teal")
plt.title('Watch Time Distribution', fontsize=16)
plt.xlabel('Hour of the Day', fontsize=14)
plt.ylabel('Frequency', fontsize=14)
plt.show()

plt.figure(figsize=(8, 6))
sns.scatterplot(x='Scroll Rate', y='Age', data=data, color="darkred")
plt.title('Scroll Rate vs. Age', fontsize=16)
plt.xlabel('Scroll Rate', fontsize=14)
plt.ylabel('Age', fontsize=14)
plt.show()

#Addiction Level vs. Self Control
plt.figure(figsize=(8, 6))
sns.scatterplot(x='Self Control', y='Addiction Level', data=data, color="orchid")
plt.title('Addiction Level vs. Self Control', fontsize=16)
plt.xlabel('Self Control', fontsize=14)
plt.ylabel('Addiction Level', fontsize=14)
plt.show()

#Productivity Loss by Watch Reason
plt.figure(figsize=(10, 6))
sns.barplot(x='ProductivityLoss', y='Watch Reason', data=data, ci=None, palette="cubehelix")
plt.title('Productivity Loss by Watch Reason', fontsize=16)
plt.xlabel('Productivity Loss', fontsize=14)
plt.ylabel('Watch Reason', fontsize=14)
plt.show()

"""###Device and Connection Analysis"""

#Device Type Distribution
plt.figure(figsize=(8, 6))
sns.countplot(x='DeviceType', data=data, palette="PuOr")
plt.title('Device Type Distribution', fontsize=16)
plt.xlabel('Device Type', fontsize=14)
plt.ylabel('Count', fontsize=14)
plt.show()

#Connection Type vs. Platform
plt.figure(figsize=(10, 6))
sns.countplot(x='Platform', hue='ConnectionType', data=data, palette="coolwarm")
plt.title('Connection Type vs. Platform', fontsize=16)
plt.xlabel('Platform', fontsize=14)
plt.ylabel('Count', fontsize=14)
plt.show()

"""###Advanced Analysis"""

#Engagement vs. Addiction Level
plt.figure(figsize=(8, 6))
sns.heatmap(data.pivot_table(index='Engagement', columns='Addiction Level', values='UserID', aggfunc='count'), cmap='coolwarm', annot=True)
plt.title('Engagement vs. Addiction Level', fontsize=16)
plt.xlabel('Addiction Level', fontsize=14)
plt.ylabel('Engagement', fontsize=14)
plt.show()

# Scatter Plot: Scroll Rate vs. Time Spent on Video
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Scroll Rate', y='Time Spent On Video', data=data, color='r', s=100)
sns.regplot(x='Scroll Rate', y='Time Spent On Video', data=data, scatter=False, color='blue')
plt.title('Scroll Rate vs. Time Spent on Video (Indicating Attention Span)')
plt.xlabel('Scroll Rate')
plt.ylabel('Time Spent on Video')
plt.grid(True)
plt.show()

# Scatter Plot: Scroll Rate vs. Engagement
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Scroll Rate', y='Engagement', data=data, color='g', s=100)
sns.regplot(x='Scroll Rate', y='Engagement', data=data, scatter=False, color='blue')
plt.title('Scroll Rate vs. Engagement')
plt.xlabel('Scroll Rate')
plt.ylabel('Engagement')
plt.grid(True)
plt.show()

# Scatter Plot: Scroll Rate vs. Satisfaction
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Scroll Rate', y='Satisfaction', data=data, color='orange', s=100)
sns.regplot(x='Scroll Rate', y='Satisfaction', data=data, scatter=False, color='blue')
plt.title('Scroll Rate vs. Satisfaction')
plt.xlabel('Scroll Rate')
plt.ylabel('Satisfaction')
plt.grid(True)
plt.show()

"""#**USER SEGMENTATION (By K means)**"""

from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

features = ['Age', 'Income', 'Engagement', 'Number of Sessions', 'Total Time Spent']

# Drop any missing values if necessary
social_media_data = data.dropna(subset=features)

# Extract the features for clustering
X = social_media_data[features]

# Standardize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Calculate the within-cluster sum of squares (inertia) for different numbers of clusters
inertia = []
range_n_clusters = range(1, 11)

for n_clusters in range_n_clusters:
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    kmeans.fit(X_scaled)
    inertia.append(kmeans.inertia_)

# Plot the Elbow curve - for finding optimal no. of clusters
# The "elbow" point is where the rate of decrease sharply slows down, indicating that adding more clusters doesn't significantly reduce the within-cluster sum of squares (WCSS) any further.)
plt.figure(figsize=(8, 6))
plt.plot(range_n_clusters, inertia, marker='o')
plt.title('Elbow Method for Optimal Number of Clusters', fontsize=16)
plt.xlabel('Number of Clusters', fontsize=14)
plt.ylabel('Inertia', fontsize=14)
plt.show()

# Set the optimal number of clusters (e.g., based on the elbow curve)
optimal_clusters = 4
# Fit the KMeans model
kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)
social_media_data['Cluster'] = kmeans.fit_predict(X_scaled)

# If you have more than 2 features, use pairplot or PCA for visualization
plt.figure(figsize=(12, 10))
sns.scatterplot(x='Age', y='Engagement', hue='Cluster', data=social_media_data, palette='viridis')
plt.title('User Segmentation by Age and Engagement', fontsize=16)
plt.xlabel('Age', fontsize=14)
plt.ylabel('Engagement', fontsize=14)
plt.show()

# Group by the clusters and analyze their characteristics
cluster_analysis = social_media_data.groupby('Cluster')[features].mean()
print(cluster_analysis)

"""## Summary Report: User Segmentation Analysis

#### Overview
The K-Means clustering algorithm was applied to segment users based on key features such as Age, Income, Engagement, Number of Sessions, and Total Time Spent. The analysis revealed four distinct user clusters with the following characteristics:

### Cluster 0: **Middle-Aged, High-Income, Moderate Engagement**
- **Age**: Average age of 38.9 years.
- **Income**: Higher average income of approximately $72,606.
- **Engagement**: Moderate engagement level with an average score of 5302.7.
- **Number of Sessions**: Lower frequency of sessions, with an average of 4.3 sessions.
- **Total Time Spent**: Moderate time spent on the platform, averaging 124 minutes.

**Interpretation**: This cluster represents middle-aged users with a relatively high income. They tend to engage moderately with the platform but do not spend much time or have frequent sessions. These users may be balancing their platform use with other activities or responsibilities.

### Cluster 1: **Younger, Low-Income, Highly Active**
- **Age**: Average age of 37.7 years.
- **Income**: Lower average income of approximately $40,720.
- **Engagement**: Highest engagement level among all clusters with an average score of 5561.4.
- **Number of Sessions**: High frequency of sessions, with an average of 12.8 sessions.
- **Total Time Spent**: Lowest time spent on the platform, averaging 80.2 minutes.

**Interpretation**: This cluster is characterized by younger users with lower incomes who are highly active on the platform. Despite their high engagement and frequent sessions, they spend less time per session. These users may be seeking quick and frequent interactions rather than prolonged engagement.

### Cluster 2: **Older, Low-Income, Moderate Activity**
- **Age**: Average age of 44.0 years.
- **Income**: Lower average income of approximately $41,108.
- **Engagement**: Moderate engagement level with an average score of 4585.3.
- **Number of Sessions**: Moderate frequency of sessions, with an average of 8.9 sessions.
- **Total Time Spent**: Highest time spent on the platform, averaging 230.9 minutes.

**Interpretation**: This cluster consists of older users with lower incomes who have moderate engagement but spend the most time on the platform. They may be using the platform as a primary source of entertainment or information, leading to longer sessions.

### Cluster 3: **Older, High-Income, Frequent Users**
- **Age**: Average age of 43.3 years.
- **Income**: Highest average income of approximately $83,144.
- **Engagement**: Lower engagement level with an average score of 4538.8.
- **Number of Sessions**: Highest frequency of sessions, with an average of 14.5 sessions.
- **Total Time Spent**: Moderate time spent on the platform, averaging 168.6 minutes.

**Interpretation**: This cluster represents older users with the highest income. They have frequent sessions but moderate overall engagement and time spent. These users likely use the platform regularly throughout the day but in shorter bursts.

### Strategic Recommendations

1. **Cluster 0**: Consider targeted content that aligns with their lifestyle, focusing on convenience and efficiency to match their moderate platform usage.
   
2. **Cluster 1**: Engage these users with frequent updates, notifications, or short-form content to maximize their high engagement and frequent sessions.

3. **Cluster 2**: Provide more in-depth content or community engagement opportunities, as these users spend significant time on the platform, likely seeking immersive experiences.

4. **Cluster 3**: Implement loyalty programs or exclusive content for these high-income, frequent users, incentivizing them to increase their engagement further.

### Conclusion
The segmentation analysis has identified clear differences in user behavior, income levels, and engagement patterns across the clusters. By leveraging these insights, the platform can tailor its strategies to better meet the needs and preferences of each user group, ultimately enhancing user satisfaction and platform growth.

#**ENGAGEMENT PREDICTION Hybrid Model -  K-Means for initial clustering, followed by a Random Forest to predict outcomes within each cluster.**
"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

# Assuming you have a target variable to predict (e.g., 'Engagement')
target_variable = 'Engagement'
features = ['Age', 'Income', 'Number of Sessions', 'Total Time Spent', 'Cluster']  # Include Cluster as a feature

# Initialize a dictionary to store models and results for each cluster
cluster_models = {}
cluster_results = {}

# Iterate over each cluster
for cluster in social_media_data['Cluster'].unique():
    # Filter the data for the current cluster
    cluster_data = social_media_data[social_media_data['Cluster'] == cluster]

    # Define the features and target
    X = cluster_data[features]
    y = cluster_data[target_variable]

    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Initialize and train the Random Forest model
    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
    rf_model.fit(X_train, y_train)

    # Predict and evaluate
    y_pred = rf_model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)

    # Store the model and the results
    cluster_models[cluster] = rf_model
    cluster_results[cluster] = {'MSE': mse, 'Predictions': y_pred}

# Display results for each cluster
for cluster, results in cluster_results.items():
    print(f"Cluster {cluster} - Mean Squared Error: {results['MSE']}")

"""## Summary Report: Hybrid Model Analysis Using K-Means and Random Forest

#### Overview
A hybrid model was developed to predict user engagement by first segmenting users into distinct clusters using K-Means clustering and then applying a Random Forest model to each cluster. The Mean Squared Error (MSE) for each cluster's model was evaluated to assess the model's performance. The results are summarized below:

### Cluster 3: **Older, High-Income, Frequent Users**
- **Mean Squared Error (MSE)**: 9,940,690
- **Summary**: This cluster, consisting of older users with high income who frequently use the platform, had the highest MSE among all clusters. Despite the frequent usage, predicting engagement for this group proved challenging, suggesting a potential variability in their behavior that the model struggled to capture.

### Cluster 2: **Older, Low-Income, Moderate Activity**
- **Mean Squared Error (MSE)**: 6,099,671
- **Summary**: This cluster, composed of older, lower-income users with moderate activity, achieved the lowest MSE, indicating that the model was more successful in predicting engagement for this group. The consistent engagement patterns and longer time spent on the platform might have contributed to the model's accuracy.

### Cluster 1: **Younger, Low-Income, Highly Active**
- **Mean Squared Error (MSE)**: 7,802,370
- **Summary**: The model's performance for this cluster, characterized by younger, lower-income users with high activity levels, was moderate. While the model captured some patterns, the relatively high MSE suggests that the engagement of this group may be influenced by factors not fully captured by the features used in the model.

### Cluster 0: **Middle-Aged, High-Income, Moderate Engagement**
- **Mean Squared Error (MSE)**: 9,936,608
- **Summary**: This cluster, consisting of middle-aged, high-income users with moderate engagement, also had a high MSE, similar to Cluster 3. This indicates that predicting engagement for users in this cluster was difficult, possibly due to the moderate and varied engagement levels.

### Key Insights

1. **Cluster 2 (Older, Low-Income, Moderate Activity)** had the best model performance, indicating that this group's engagement was more predictable. The consistent behavior of these users might have contributed to the lower error.

2. **Clusters 3 and 0** (Older, High-Income, Frequent Users and Middle-Aged, High-Income, Moderate Engagement) had the highest MSEs, suggesting that these groups exhibit more complex or less consistent engagement patterns, making predictions more challenging.

3. **Cluster 1 (Younger, Low-Income, Highly Active)** showed moderate predictability. The diverse engagement behaviors within this group might have led to variability in model performance.

### Recommendations

1. **Further Feature Engineering**: Consider incorporating additional features such as user preferences, content types consumed, or social interactions to improve model accuracy, especially for clusters with high MSEs.

2. **Model Optimization**: Experiment with different hyperparameters for the Random Forest models or explore other algorithms (e.g., Gradient Boosting Machines, XGBoost) to enhance prediction accuracy within each cluster.

3. **Cluster Reassessment**: Reevaluate the clustering approach. If certain clusters consistently show high MSEs, it might be worth exploring different clustering techniques or increasing the number of clusters to capture more nuanced user segments.

### Conclusion
The hybrid model approach, combining K-Means clustering with Random Forest models, provided valuable insights into user engagement patterns. While it showed promise, particularly for certain user segments, further refinement and exploration are necessary to fully leverage its predictive power. The findings underscore the importance of tailored models for different user segments and suggest potential areas for improvement in model accuracy and user segmentation.

#**BEHAVIOURAL ANALYSIS - Decision Tree Regressor and Random Forest Regressor**
"""

from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Encode categorical variables
from sklearn.preprocessing import LabelEncoder
label_encoders = {}
for column in data.select_dtypes(include=['object', 'bool']).columns:
    le = LabelEncoder()
    data[column] = le.fit_transform(data[column])
    label_encoders[column] = le

# Define features and targets for Addiction Level and ProductivityLoss
features = data.drop(columns=['Addiction Level', 'ProductivityLoss', 'UserID'])
target_addiction = data['Addiction Level']
target_productivity = data['ProductivityLoss']

# Split data into training and testing sets
X_train_add, X_test_add, y_train_add, y_test_add = train_test_split(features, target_addiction, test_size=0.2, random_state=42)
X_train_prod, X_test_prod, y_train_prod, y_test_prod = train_test_split(features, target_productivity, test_size=0.2, random_state=42)

# Function to train and evaluate models
def train_and_evaluate(X_train, X_test, y_train, y_test, target_name):
    # Decision Tree
    tree_model = DecisionTreeRegressor(random_state=42)
    tree_model.fit(X_train, y_train)
    y_pred_tree = tree_model.predict(X_test)

    # Random Forest
    forest_model = RandomForestRegressor(random_state=42)
    forest_model.fit(X_train, y_train)
    y_pred_forest = forest_model.predict(X_test)

    # Evaluation
    print(f"--- {target_name} ---")
    print("Decision Tree:")
    print(f"  MSE: {mean_squared_error(y_test, y_pred_tree):.2f}")
    print(f"  R^2: {r2_score(y_test, y_pred_tree):.2f}")

    print("Random Forest:")
    print(f"  MSE: {mean_squared_error(y_test, y_pred_forest):.2f}")
    print(f"  R^2: {r2_score(y_test, y_pred_forest):.2f}")

    # Feature Importance
    importances = forest_model.feature_importances_
    indices = np.argsort(importances)[::-1]

    plt.figure(figsize=(10, 6))
    plt.title(f"Feature Importance - {target_name}")
    plt.bar(range(X_train.shape[1]), importances[indices], align="center")
    plt.xticks(range(X_train.shape[1]), [X_train.columns[i] for i in indices], rotation=90)
    plt.tight_layout()
    plt.show()

# Train and evaluate models for Addiction Level
train_and_evaluate(X_train_add, X_test_add, y_train_add, y_test_add, "Addiction Level")

# Train and evaluate models for ProductivityLoss
train_and_evaluate(X_train_prod, X_test_prod, y_train_prod, y_test_prod, "ProductivityLoss")

#for UI -- this is for predicting
#addiction_prediction = forest_model.predict(input_df)
#productivity_loss_prediction = forest_model_prod.predict(input_df)

#print(f"Predicted Addiction Level: {addiction_prediction[0]}")
#print(f"Predicted Productivity Loss: {productivity_loss_prediction[0]}")

"""The models for both ProductivityLoss and Addiction Level performed exceptionally well. Both the Decision Tree and Random Forest models achieved a Mean Squared Error (MSE) of 0.00 and an R² score of 1.00, indicating perfect predictions on the test data. This suggests that the models captured the relationships in the data perfectly, though it's important to validate these results on unseen data to ensure they are not overfitting."""

